import pandas as pd 
import numpy as np  
from sklearn.model_selection import train_test_split  # veriyi eÄŸitim ve test setine bÃ¶lmek iÃ§in kullanÄ±lÄ±r
from sklearn.preprocessing import LabelEncoder, StandardScaler  # LabelEncoder: kategorik deÄŸiÅŸkenleri sayÄ±sal hale getirir, StandardScaler: veriyi normalize eder
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, IsolationForest  # RandomForestClassifier/Regressor: sÄ±nÄ±flandÄ±rma ve regresyon iÃ§in, IsolationForest: anomali tespiti
from sklearn.cluster import KMeans  # KMeans: kullanÄ±cÄ± davranÄ±ÅŸlarÄ±nÄ± gruplamak iÃ§in kÃ¼meleme algoritmasÄ±
from prophet import Prophet  # Prophet: zaman serisi tahmini iÃ§in kullanÄ±lan model
import logging  # logging: hata ve uyarÄ±larÄ± yÃ¶netmek iÃ§in kullanÄ±lÄ±r
import matplotlib.pyplot as plt
import seaborn as sns


# logging seviyelerini dÃ¼ÅŸÃ¼rerek fazla mesaj Ã§Ä±kmasÄ±nÄ± engelliyoruz
logging.getLogger("cmdstanpy").setLevel(logging.ERROR)  # Prophet iÃ§indeki cmdstanpy kÃ¼tÃ¼phanesinin hatalarÄ±nÄ± bastÄ±rÄ±r
logging.getLogger('prophet').setLevel(logging.ERROR)  # Prophet uyarÄ±larÄ±nÄ± bastÄ±rÄ±r

# ---------------- Veri YÃ¼kleme ----------------
#KullanÄ±rken veriyi kendi bilgisayarÄ±na yÃ¼kleyerek kendi dosya yolunu gir
dosya_yolu = r"C:\Users\Aykut\.cache\kagglehub\datasets\dasgroup\rba-dataset\versions\1\rba-dataset.csv"
#KullanÄ±rken veriyi kendi bilgisayarÄ±na yÃ¼kleyerek kendi dosya yolunu gir

df = pd.read_csv(dosya_yolu, nrows=2_000_000)

df["Login Successful"] = df["Login Successful"].astype(int)  # BaÅŸarÄ±lÄ± login bilgisini integer yapÄ±yoruz, ML modelleri string kabul etmez.
df = df.fillna("Bilinmiyor")  # BoÅŸ deÄŸerleri "Bilinmiyor" ile dolduruyoruz, boÅŸ bÄ±rakÄ±lÄ±rsa encoding veya model Ã§alÄ±ÅŸmaz.
df["Round-Trip Time [ms]"] = pd.to_numeric(df["Round-Trip Time [ms]"], errors="coerce").fillna(0)# Round-Trip Time sayÄ±sal olmayan deÄŸerleri zorla sayÄ±ya Ã§eviriyoruz, NaN olursa 0 ile dolduruyoruz. Model sayÄ±sal deÄŸer bekler.

df['Login Timestamp'] = pd.to_datetime(df['Login Timestamp'], errors='coerce')  
# Tarihleri datetime formatÄ±na Ã§eviriyoruz, bÃ¶ylece saat ve gÃ¼n Ã§Ä±karabiliriz. Olmazsa saat/gÃ¼n hesaplanamaz.
df['saat'] = df['Login Timestamp'].dt.hour  # Saat bilgisini datetime'dan Ã§ekiyoruz, zaman bazlÄ± tahmin iÃ§in gerekli.
df['gun'] = df['Login Timestamp'].dt.dayofweek  # HaftanÄ±n gÃ¼nÃ¼nÃ¼ 0-6 arasÄ± sayÄ±sal olarak alÄ±yoruz, zaman bazlÄ± analiz iÃ§in lazÄ±m.

gun_dict = {0: 'Pazartesi', 1: 'SalÄ±', 2: 'Ã‡arÅŸamba', 3: 'PerÅŸembe', 4: 'Cuma', 5: 'Cumartesi', 6: 'Pazar'}  

# ---------------- Label Encoding ----------------
label_cols = ["OS Name and Version", "Device Type", "Browser Name and Version", "Country", "Region", "City", "ASN"]  
# Kategorik sÃ¼tunlarÄ± listeledik, Ã§Ã¼nkÃ¼ ML modelleri sayÄ±sal veri ister.
encoders = {}  # Her sÃ¼tun iÃ§in encoder saklayacaÄŸÄ±z.

for col in label_cols:
    le = LabelEncoder()  # LabelEncoder ile kategorik veriyi sayÄ±sala Ã§eviriyoruz.
    df[col+'_enc'] = le.fit_transform(df[col].astype(str))  
    # SayÄ±sal olmayan kategorik veriyi sayÄ±sal koda Ã§eviriyoruz. Olmazsa ML modeli hata verir.
    encoders[col] = le  # Daha sonra tersini almak iÃ§in encoder kaydediyoruz.
# ---------------- Fonksiyonlar ----------------
def os_device_model(df):
    X = df[[col+'_enc' for col in ["OS Name and Version", "Device Type"]]]# Model iÃ§in girdi deÄŸiÅŸkenleri: OS ve cihaz tipi sayÄ±sal kodlarÄ±
    y = df["Login Successful"]# Hedef deÄŸiÅŸken: Login baÅŸarÄ±lÄ± mÄ±?

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)# Veriyi eÄŸitim ve test olarak ayÄ±rÄ±yoruz. Modelin doÄŸruluÄŸunu test iÃ§in kullanacaÄŸÄ±z.

    model = RandomForestClassifier(n_estimators=300, max_depth=20, random_state=42, n_jobs=-1)# Random Forest classifier: login olasÄ±lÄ±ÄŸÄ± tahmini iÃ§in. Ã‡ok sayÄ±da aÄŸaÃ§ ve maksimim derinlik belirleniyor.
    model.fit(X_train, y_train)# Modeli eÄŸitiyoruz

    y_pred_prob = model.predict_proba(X_test)[:,1]# Login olasÄ±lÄ±ÄŸÄ± tahmini, 0-1 arasÄ±

    sonuc = X_test.copy()  
    for col in ["OS Name and Version", "Device Type"]:
        sonuc[col] = encoders[col].inverse_transform(sonuc[col+'_enc']) # SayÄ±sal kodlarÄ± tekrar orijinal kategoriye Ã§eviriyoruz, okunabilir Ã§Ä±ktÄ± iÃ§in.
    sonuc['login_olasilik'] = y_pred_prob*100  # OlasÄ±lÄ±ÄŸÄ± % olarak gÃ¶steriyoruz

    print("---- OS/Device BazlÄ± Login OlasÄ±lÄ±klarÄ± ----")
    print(sonuc[[ "OS Name and Version", "Device Type", "login_olasilik"]].head(20))  # Ä°lk 20 Ã¶rneÄŸi gÃ¶steriyoruz

def saat_gun_model(df):
    cols = ['gun','saat'] + [col+'_enc' for col in ["OS Name and Version", "Device Type", "Browser Name and Version"]]     # Girdi deÄŸiÅŸkenleri: gÃ¼n, saat ve ek kategorik Ã¶zellikler
    login_counts = df.groupby(cols).size().reset_index(name='login_sayisi')     # Her kombinasyon iÃ§in login sayÄ±sÄ±nÄ± sayÄ±yoruz

    X = login_counts[cols]
    y = login_counts['login_sayisi']   # Model girdi ve hedef deÄŸiÅŸkenler

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # EÄŸitim/test ayÄ±rÄ±mÄ±

    model = RandomForestRegressor(n_estimators=300, max_depth=20, random_state=42, n_jobs=-1)   # Random Forest Regressor ile sayÄ±sal login tahmini yapÄ±yoruz
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test) # Test seti iÃ§in tahmin

    sonuc = X_test.copy()
    sonuc['tahmini_login'] = y_pred.round().astype(int)   # Tahmini login sayÄ±sÄ±nÄ± yuvarlayÄ±p integer yapÄ±yoruz
    for col in ["OS Name and Version", "Device Type", "Browser Name and Version"]:
        sonuc[col] = encoders[col].inverse_transform(sonuc[col+'_enc'].astype(int)) # KodlarÄ± kategoriye geri Ã§eviriyoruz
    sonuc['gun'] = sonuc['gun'].map(gun_dict)   # GÃ¼nleri isimle eÅŸleÅŸtiriyoruz

    print("---- Saat/GÃ¼n + Ek Ã–zellikler BazlÄ± Tahmini Login SayÄ±sÄ± ----")
    print(sonuc[['gun','saat','OS Name and Version','Device Type','Browser Name and Version','tahmini_login']].head(20)) # Ä°lk 20 tahmini gÃ¶steriyoruz

def gelecek_hafta_tahmin(df):
    # GÃ¼nlÃ¼k login sayÄ±sÄ±
    gunluk_logins = df.groupby(df['Login Timestamp'].dt.date).size().reset_index(name='y')
    gunluk_logins['ds'] = pd.to_datetime(gunluk_logins['Login Timestamp'])

    # Eksik gÃ¼nleri doldur
    tarih_araligi = pd.date_range(start=gunluk_logins['ds'].min(), end=gunluk_logins['ds'].max())
    gunluk_logins = (
        gunluk_logins
        .set_index('ds')
        .reindex(tarih_araligi, fill_value=0)
        .rename_axis('ds')
        .reset_index()
    )

    # Veri yetersizse Ã§Ä±k
    if len(gunluk_logins) < 7:
        print("Yeterli veri yok, tahmin Ã¼retilemiyor.")
        return

    # Prophet modeli ile tahmin
    prophet_model = Prophet(daily_seasonality=True)
    prophet_model.fit(gunluk_logins[['ds', 'y']])

    # Gelecek 28 gÃ¼n iÃ§in tahmin Ã¼ret
    gelecek_28_gun = prophet_model.make_future_dataframe(periods=28)
    tahmin = prophet_model.predict(gelecek_28_gun)

    # HaftalÄ±k toplamlarÄ± Pazartesi baÅŸlangÄ±Ã§lÄ± olarak grupla
    haftalik_tahmin = (
        tahmin[['ds', 'yhat']]
        .set_index('ds')
        .resample('W-MON')  # Pazartesi baÅŸlangÄ±Ã§lÄ± haftalÄ±k Ã¶rnekleme
        .sum()
        .reset_index()
        .rename(columns={'ds': 'Hafta', 'yhat': 'Tahmini Login'})
    )

    # Tahmini login sayÄ±sÄ±nÄ± tam sayÄ±ya Ã§evir
    haftalik_tahmin['Tahmini Login'] = haftalik_tahmin['Tahmini Login'].round().astype(int)

    # Sadece son 4 haftayÄ± al
    haftalik_tahmin = haftalik_tahmin.tail(4).reset_index(drop=True)

    # ğŸ¨ GÃ¶rselleÅŸtirme
    plt.figure(figsize=(10,6))
    sns.barplot(
        data=haftalik_tahmin,
        x='Hafta',
        y='Tahmini Login',
        hue='Hafta',

        palette='crest',
        legend=False  # uyarÄ±yÄ± engeller
    )
    plt.title("Gelecek 4 Hafta Login Tahmini", fontsize=14, weight='bold', pad=20)
    plt.xlabel("Hafta BaÅŸlangÄ±cÄ±", fontsize=12)
    plt.ylabel("Tahmini Login SayÄ±sÄ±", fontsize=12)
    plt.xticks(rotation=45, ha='right')

    # Her sÃ¼tunun Ã¼stÃ¼ne deÄŸer yaz
    for index, value in enumerate(haftalik_tahmin['Tahmini Login']):
        plt.text(index, value + (value*0.02), str(value), ha='center', va='bottom', fontsize=10, weight='bold')

    plt.tight_layout()
    plt.show()

    # Tablo olarak yazdÄ±r
    print("---- Gelecek 4 Hafta Login Tahmini ----")
    print(haftalik_tahmin.to_string(index=False))


def kullanici_saat_gun_model(df):
    cols = ['gun','saat'] + [col+'_enc' for col in ["OS Name and Version", "Device Type"]]   # Girdi deÄŸiÅŸkenleri: gÃ¼n, saat ve OS + cihaz tipi kodlarÄ±
    X = df[cols]
    y = df['Login Successful']  # Hedef deÄŸiÅŸken: login baÅŸarÄ±lÄ± mÄ±?

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # EÄŸitim ve test seti oluÅŸtur

    model = RandomForestClassifier(n_estimators=300, max_depth=20, random_state=42, n_jobs=-1)  # Random Forest classifier
    model.fit(X_train, y_train)

    y_pred_prob = model.predict_proba(X_test)[:,1]   # Login olasÄ±lÄ±ÄŸÄ± tahmini

    sonuc = X_test.copy()
    sonuc['login_olasilik'] = y_pred_prob*100   # % olarak gÃ¶ster

    for col in ["OS Name and Version", "Device Type"]:
        sonuc[col] = encoders[col].inverse_transform(sonuc[col+'_enc'])     # KodlarÄ± kategoriye geri Ã§evir

    sonuc['gun'] = sonuc['gun'].map(gun_dict)  # GÃ¼n isimlerini yazdÄ±r

    print("---- KullanÄ±cÄ± BazlÄ± Saat/GÃ¼n Login OlasÄ±lÄ±klarÄ± ----")
    print(sonuc[['gun','saat','OS Name and Version','Device Type','login_olasilik']].head(20))

def os_4haftalik_tahmin(df):
    populer_os = df["OS Name and Version"].value_counts().head(3).index.tolist()# En popÃ¼ler 3 iÅŸletim sistemi seÃ§iliyor; en Ã§ok login yapan OS'ler iÃ§in tahmin yapÄ±lacak
    tum_tahminler = []  # TÃ¼m OS'ler iÃ§in haftalÄ±k tahminler buraya eklenecek

    for os_name in populer_os:
        df_os = df[df["OS Name and Version"] == os_name].copy()# Sadece ilgili OS iÃ§in veri alÄ±yoruz
        df_os['tarih'] = pd.to_datetime(df_os['Login Timestamp'].dt.date)# Tarih sÃ¼tunu oluÅŸturuyoruz; Prophet iÃ§in 'ds' sÃ¼tunu gerekli
        gunluk_logins = df_os.groupby('tarih').size().reset_index(name='y')# GÃ¼nlÃ¼k login sayÄ±sÄ±nÄ± hesaplÄ±yoruz

        # Veri yetersizse tahmin yapamayÄ±z, minimum 7 gÃ¼n veri gerekiyor
        if len(gunluk_logins) < 7:
            continue

        prophet_model = Prophet(daily_seasonality=True)# Prophet modeli oluÅŸturuluyor; gÃ¼nlÃ¼k sezonluk davranÄ±ÅŸÄ± yakalamasÄ± iÃ§in daily_seasonality=True
        prophet_model.fit(gunluk_logins.rename(columns={'tarih':'ds'}))# Prophet modelini veriyle eÄŸitiyoruz
        gelecek_28_gun = prophet_model.make_future_dataframe(periods=28) # Gelecek 28 gÃ¼n iÃ§in tahmin yapÄ±lacak dataframe    
        tahmin = prophet_model.predict(gelecek_28_gun)    # Tahminler oluÅŸturuluyor

        gelecek = tahmin[['ds','yhat']].tail(28).copy()    # Sadece son 28 gÃ¼nÃ¼n tahminini alÄ±yoruz
        gelecek['Tahmini Login'] = gelecek['yhat'].round().astype(int)  # Tahmini login sayÄ±sÄ±nÄ± integer yapÄ±yoruz      
        gelecek['OS Name and Version'] = os_name  # OS bilgisini ekliyoruz        
        gelecek['Hafta'] = gelecek['ds'].dt.to_period('W').astype(str)# HaftalÄ±k gruplama iÃ§in tarihleri haftaya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz

        tum_tahminler.append(       # HaftalÄ±k toplam tahmini login sayÄ±sÄ±nÄ± ekliyoruz
            gelecek.groupby(['Hafta','OS Name and Version'])['Tahmini Login'].sum().reset_index()
        )

    if tum_tahminler:
        # TÃ¼m OS'ler iÃ§in tahminleri birleÅŸtiriyoruz
        os_tahmin_df = pd.concat(tum_tahminler, ignore_index=True)
        os_tahmin_df = os_tahmin_df.groupby(['OS Name and Version']).tail(4).reset_index(drop=True)
        
        print("---- OS BazlÄ± Gelecek 4 Hafta Login Tahmini ----")
        print(os_tahmin_df.iloc[0:12])
    else:
        print("HiÃ§bir OS iÃ§in tahmin Ã¼retilemedi.")

def anomali_tespiti(df, contamination=0.1, verbose=True):
    # Tarih ve saat sÃ¼tunlarÄ±nÄ± oluÅŸturuyoruz; saat sadece gÃ¼nlÃ¼k davranÄ±ÅŸÄ±n varyansÄ±nÄ± Ã¶lÃ§mek iÃ§in
    df["Tarih"] = pd.to_datetime(df["Login Timestamp"]).dt.date
    df["Saat"] = pd.to_datetime(df["Login Timestamp"]).dt.hour

    # KullanÄ±cÄ±-gÃ¼n bazlÄ± Ã¶zet: login sayÄ±sÄ±, saat std, farklÄ± cihaz/OS/ÅŸehir sayÄ±sÄ±
    user_daily = df.groupby(["User ID", "Tarih"]).agg({
        "Saat": ["count", "std"],
        "Device Type": "nunique",
        "OS Name and Version": "nunique",
        "City": "nunique"
    }).reset_index()

    # Kolon isimlerini anlaÅŸÄ±lÄ±r hale getiriyoruz
    user_daily.columns = ["KullanÄ±cÄ± ID", "Tarih", "GÃ¼nlÃ¼k Login SayÄ±sÄ±", 
                          "Login Saati Std", "FarklÄ± Cihaz SayÄ±sÄ±", 
                          "FarklÄ± OS SayÄ±sÄ±", "FarklÄ± Åehir SayÄ±sÄ±"]
    
    user_daily["Login Saati Std"] = user_daily["Login Saati Std"].fillna(0)    # Std boÅŸsa 0 olarak ayarlanÄ±r; model bozulmasÄ±n diye

    # KullanÄ±cÄ± bazÄ±nda ortalama ve std login sayÄ±sÄ± hesaplÄ±yoruz
    user_stats = user_daily.groupby("KullanÄ±cÄ± ID")["GÃ¼nlÃ¼k Login SayÄ±sÄ±"].agg(["mean", "std"])
    user_stats.columns = ["Ort_Login", "Std_Login"]
    # KullanÄ±cÄ±-gÃ¼n dataframe'i ile birleÅŸtiriyoruz
    user_daily = user_daily.merge(user_stats, left_on="KullanÄ±cÄ± ID", right_index=True)
    user_daily["Login SapmasÄ±"] = user_daily["GÃ¼nlÃ¼k Login SayÄ±sÄ±"] - user_daily["Ort_Login"]   # Login sapmasÄ±nÄ± hesaplÄ±yoruz; kullanÄ±cÄ± ortalamasÄ±na gÃ¶re fark

    feature_cols = ["GÃ¼nlÃ¼k Login SayÄ±sÄ±", "Login SapmasÄ±", "Login Saati Std",    # Anomali tespiti iÃ§in kullanÄ±lacak Ã¶zellikler
                    "FarklÄ± Cihaz SayÄ±sÄ±", "FarklÄ± OS SayÄ±sÄ±", "FarklÄ± Åehir SayÄ±sÄ±"]

    X_scaled = StandardScaler().fit_transform(user_daily[feature_cols].fillna(0)) # Ã–zellikleri Ã¶lÃ§eklendiriyoruz; IsolationForest iÃ§in gereklidir

    predictions = IsolationForest(contamination=contamination, random_state=42, n_estimators=200).fit_predict(X_scaled)
    user_daily["Anormal Mi?"] = np.where(predictions == -1, "Anormal", "Normal") # IsolationForest ile anomali tahmini; -1 anormal, 1 normal

    if verbose:
        print("\n--- Anomali Tespit SonuÃ§larÄ± ---")
        display_cols = ["KullanÄ±cÄ± ID", "Tarih", "GÃ¼nlÃ¼k Login SayÄ±sÄ±", 
                        "Login Saati Std", "FarklÄ± Cihaz SayÄ±sÄ±", "FarklÄ± OS SayÄ±sÄ±", 
                        "FarklÄ± Åehir SayÄ±sÄ±", "Anormal Mi?"]
        print(user_daily[display_cols].iloc[1:51]) 
    return user_daily    # Anormal etiketlenmiÅŸ dataframe'i dÃ¶ndÃ¼rÃ¼yoruz

def benzer_login_siniflandir(df, n_clusters=7, verbose=True):
    # Tarih ve saat bilgilerini Ã§Ä±karÄ±yoruz
    df["Tarih"] = pd.to_datetime(df["Login Timestamp"]).dt.date
    df["Saat"] = pd.to_datetime(df["Login Timestamp"]).dt.hour
    df["Haftanin Gunu"] = pd.to_datetime(df["Login Timestamp"]).dt.dayofweek  # Pazartesi=0

    # KullanÄ±cÄ±-gÃ¼n bazlÄ± Ã¶zet oluÅŸturuluyor
    user_daily = df.groupby(["User ID", "Tarih"]).agg({
        "Saat": ["count", "mean", "std"],
        "Device Type": "nunique",
        "OS Name and Version": "nunique",
        "City": "nunique"
    }).reset_index()

    # Kolon isimlerini anlamlÄ± yapÄ±yoruz
    user_daily.columns = ["KullanÄ±cÄ± ID", "Tarih", "GÃ¼nlÃ¼k Login SayÄ±sÄ±", "Login Saati Ort",
                          "Login Saati Std", "FarklÄ± Cihaz SayÄ±sÄ±", "FarklÄ± OS SayÄ±sÄ±", "FarklÄ± Åehir SayÄ±sÄ±"]

    user_daily["Login Saati Std"] = user_daily["Login Saati Std"].fillna(0)

    # Yeni Ã¶zellikler
    user_daily["Login Saati Ort"] = user_daily["Login Saati Ort"].fillna(0)
    user_daily["Cihaz Orani"] = user_daily["FarklÄ± Cihaz SayÄ±sÄ±"] / user_daily["GÃ¼nlÃ¼k Login SayÄ±sÄ±"]
    user_daily["Sehir Orani"] = user_daily["FarklÄ± Åehir SayÄ±sÄ±"] / user_daily["GÃ¼nlÃ¼k Login SayÄ±sÄ±"]

    feature_cols = ["GÃ¼nlÃ¼k Login SayÄ±sÄ±", "Login Saati Ort", "Login Saati Std",
                    "FarklÄ± Cihaz SayÄ±sÄ±", "Cihaz Orani",
                    "FarklÄ± OS SayÄ±sÄ±", "FarklÄ± Åehir SayÄ±sÄ±", "Sehir Orani"]

    # Ã–zellikleri Ã¶lÃ§eklendirme
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(user_daily[feature_cols].fillna(0))

   # KMeans ile kullanÄ±cÄ±larÄ± gruplara ayÄ±rÄ±yoruz
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    user_daily["DavranÄ±ÅŸ Grubu"] = kmeans.fit_predict(X_scaled) + 1  # 1â€™den baÅŸlatÄ±yoruz

    if verbose:
        print(f"Toplam kullanÄ±cÄ±-gÃ¼n kayÄ±t sayÄ±sÄ±: {len(user_daily)}")
        print("\n--- DavranÄ±ÅŸ GruplarÄ± Ã–zeti ---")
        for i in range(1, n_clusters + 1):  # ğŸ”¹ 1â€™den n_clustersâ€™a kadar
            grup = user_daily[user_daily["DavranÄ±ÅŸ Grubu"] == i]
            print(f"\nGrup {i} ({len(grup)} kullanÄ±cÄ±-gÃ¼n):")
            print(f"  Ort Login: {grup['GÃ¼nlÃ¼k Login SayÄ±sÄ±'].mean():.1f}")
            print(f"  Ort Login Saati: {grup['Login Saati Ort'].mean():.1f}")
            print(f"  Ort Saat Std: {grup['Login Saati Std'].mean():.2f}")
            print(f"  Ort Cihaz: {grup['FarklÄ± Cihaz SayÄ±sÄ±'].mean():.1f}, Cihaz Orani: {grup['Cihaz Orani'].mean():.2f}")
            print(f"  Ort OS: {grup['FarklÄ± OS SayÄ±sÄ±'].mean():.1f}")
            print(f"  Ort Åehir: {grup['FarklÄ± Åehir SayÄ±sÄ±'].mean():.1f}, Sehir Orani: {grup['Sehir Orani'].mean():.2f}")
    return scaler, user_daily
                            #----MENÃœ----
while True:
    print("\n---- MenÃ¼ ----")
    secim = input(
        "1- OS/Device BazlÄ± Tahmin\n"
        "2- Saat/GÃ¼n BazlÄ± Tahmin\n"
        "3- Gelecek Hafta Tahmini\n"
        "4- KullanÄ±cÄ± BazlÄ± Saat/GÃ¼n Tahmini\n"
        "5- OS/Device BazlÄ± Login SayÄ±sÄ± Tahmini (Zaman Serisi)\n"
        "6- Anomali tespiti\n"
        "7- Benzer Login DavranÄ±ÅŸlarÄ±\n"
        "8- Ã‡Ä±kÄ±ÅŸ\n"
        "SeÃ§iminiz: "
    )
    if secim == '1': os_device_model(df)
    elif secim == '2': saat_gun_model(df)
    elif secim == '3': gelecek_hafta_tahmin(df)
    elif secim == '4': kullanici_saat_gun_model(df)
    elif secim == '5': os_4haftalik_tahmin(df)
    elif secim == '6': anomali_tespiti(df)
    elif secim == '7': benzer_login_siniflandir(df)
    elif secim == '8':
        print("Ã‡Ä±kÄ±ÅŸ YapÄ±lÄ±yor...")
        break
    else:
        print("GeÃ§ersiz seÃ§im! Tekrar deneyiniz.")